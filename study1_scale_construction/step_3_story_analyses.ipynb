{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc82838b",
   "metadata": {},
   "source": [
    "# Analysis of Survey Data III: Proof Of Concept Analyses\n",
    "\n",
    "In here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a387af",
   "metadata": {},
   "source": [
    "## Import Packages And Configure Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ebdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "# Visualization modules\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "# Data analysis modules\n",
    "import factor_analyzer as fa\n",
    "import pingouin as pg\n",
    "import scipy.stats as stats\n",
    "# sklearn\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures as polyfeat\n",
    "from sklearn.linear_model import LinearRegression as linreg\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "# statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdde3ba",
   "metadata": {},
   "source": [
    "## Read in and prepare the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38dc694d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>story_id</th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>preset_label</th>\n",
       "      <th>sample</th>\n",
       "      <th>full_story</th>\n",
       "      <th>word_count</th>\n",
       "      <th>coherence</th>\n",
       "      <th>quality_innovativeness</th>\n",
       "      <th>pace</th>\n",
       "      <th>consistent_characterizations</th>\n",
       "      <th>avoiding_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_3LZPTbqxmeWvp7w</td>\n",
       "      <td>GEN_HF_6</td>\n",
       "      <td>High Fantasy</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Community</td>\n",
       "      <td>The sun was high in the sky when they arrived ...</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.657770</td>\n",
       "      <td>1.173624</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>0.330821</td>\n",
       "      <td>1.756303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_3CCMkj9T7UgOtgP</td>\n",
       "      <td>ALL_HR_3</td>\n",
       "      <td>Historical Romance</td>\n",
       "      <td>All-Nighter</td>\n",
       "      <td>Community</td>\n",
       "      <td>The first time he saw her, the sight of her wa...</td>\n",
       "      <td>1239</td>\n",
       "      <td>-0.397104</td>\n",
       "      <td>-1.179955</td>\n",
       "      <td>1.498428</td>\n",
       "      <td>0.690870</td>\n",
       "      <td>0.668291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_3PBKFhmDXlAQNO6</td>\n",
       "      <td>ALL_HOR_2</td>\n",
       "      <td>Horror</td>\n",
       "      <td>All-Nighter</td>\n",
       "      <td>Community</td>\n",
       "      <td>I woke up to hear knocking on glass. At first,...</td>\n",
       "      <td>1134</td>\n",
       "      <td>-1.723797</td>\n",
       "      <td>-1.085967</td>\n",
       "      <td>1.398710</td>\n",
       "      <td>-1.136312</td>\n",
       "      <td>0.234058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         response_id   story_id        prompt_label preset_label     sample  \\\n",
       "0  R_3LZPTbqxmeWvp7w   GEN_HF_6        High Fantasy      Genesis  Community   \n",
       "1  R_3CCMkj9T7UgOtgP   ALL_HR_3  Historical Romance  All-Nighter  Community   \n",
       "2  R_3PBKFhmDXlAQNO6  ALL_HOR_2              Horror  All-Nighter  Community   \n",
       "\n",
       "                                          full_story  word_count  coherence  \\\n",
       "0  The sun was high in the sky when they arrived ...        1105   0.657770   \n",
       "1  The first time he saw her, the sight of her wa...        1239  -0.397104   \n",
       "2  I woke up to hear knocking on glass. At first,...        1134  -1.723797   \n",
       "\n",
       "   quality_innovativeness      pace  consistent_characterizations  \\\n",
       "0                1.173624  0.485830                      0.330821   \n",
       "1               -1.179955  1.498428                      0.690870   \n",
       "2               -1.085967  1.398710                     -1.136312   \n",
       "\n",
       "   avoiding_repetition  \n",
       "0             1.756303  \n",
       "1             0.668291  \n",
       "2             0.234058  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survey response data\n",
    "aiss = pd.read_csv(\"data/aiss_factors.csv\",\n",
    "                   index_col=0)\n",
    "aiss.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269212fa",
   "metadata": {},
   "source": [
    "# Analyze Impact of Preset & Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "tidy = aiss[[\"response_id\", \"prompt_label\",\n",
    "             \"tss_coh\", \"tss_cre\", \"tss_avoid_rep\", \"tss_pac\", \"tss_conch\"]\n",
    "            ].melt(id_vars=['response_id', \"prompt_label\"])\n",
    "\n",
    "ax = sns.catplot(data=tidy,\n",
    "                 kind=\"bar\",\n",
    "                 y=\"value\", x=\"variable\", hue=\"prompt_label\",\n",
    "                 ci=90, height=5, aspect=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "tidy = aiss[[\"response_id\", \"preset_label\",\n",
    "             \"tss_coh\", \"tss_cre\", \"tss_avoid_rep\", \"tss_pac\", \"tss_conch\"]\n",
    "            ].melt(id_vars=['response_id', \"preset_label\"])\n",
    "\n",
    "ax = sns.catplot(data=tidy,\n",
    "                 kind=\"bar\",\n",
    "                 y=\"value\", x=\"variable\", hue=\"preset_label\",\n",
    "                 ci=90, height=5, aspect=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cba78",
   "metadata": {},
   "source": [
    "## Use Word Count as a Control Variable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, figsize=(10, 20))\n",
    "fig.tight_layout(pad=5.0)\n",
    "plt.grid(False)\n",
    "\n",
    "sns.regplot(data=aiss, y=\"tss_coh\",\n",
    "            x=\"word_count\", lowess=True, ax=axes[0])\n",
    "sns.regplot(data=aiss, y=\"tss_avoid_rep\",\n",
    "            x=\"word_count\", lowess=True, ax=axes[1])\n",
    "sns.regplot(data=aiss, y=\"tss_pac\",\n",
    "            x=\"word_count\", lowess=True, ax=axes[2])\n",
    "sns.regplot(data=aiss, y=\"tss_cre\",\n",
    "            x=\"word_count\", lowess=True, ax=axes[3])\n",
    "sns.regplot(data=aiss, y=\"tss_conch\",\n",
    "            x=\"word_count\", lowess=True, ax=axes[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39875f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up k-fold cross validation\n",
    "\n",
    "kf = KFold(10, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining predictors for models\n",
    "aiss[\"words_cent\"] = aiss[\"word_count\"].apply(\n",
    "    lambda x: x-aiss[\"word_count\"].mean())  # centering\n",
    "\n",
    "aiss[\"words_cent**2\"] = aiss[\"words_cent\"]*aiss[\"words_cent\"]\n",
    "aiss[\"words_cent**3\"] = aiss[\"words_cent\"]**3\n",
    "#aiss[\"words_cent**4\"] = aiss[\"words_cent\"]**4\n",
    "#aiss[\"words_cent**5\"] = aiss[\"words_cent\"]**5\n",
    "\n",
    "lin_model = linreg()\n",
    "\n",
    "pred_li = [(\"linear\", \"words_cent\"), (\"quadratic\", \"words_cent**2\"),\n",
    "           (\"cubic\", \"words_cent**3\")]\n",
    "#(\"quartic\", \"words_cent**4\"),\n",
    "# (\"quintic\", \"words_cent**5\")]\n",
    "outcome_li = [\"tss_coh\", \"tss_cre\", \"tss_avoid_rep\", \"tss_pac\", \"tss_conch\"]\n",
    "\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    y = aiss[outcome]\n",
    "    current_preds_col = []\n",
    "\n",
    "    for pred in pred_li:\n",
    "        current_preds_col.append(pred[1])\n",
    "        x = aiss.loc[:, current_preds_col]\n",
    "\n",
    "        current_model_name = pred[0]\n",
    "\n",
    "        cross_val = cross_validate(lin_model, x, y,\n",
    "                                   scoring=[\"neg_mean_squared_error\", \"r2\"], cv=kf)\n",
    "\n",
    "        neg_mses = cross_val[\"test_neg_mean_squared_error\"]\n",
    "        r_squares = cross_val[\"test_r2\"]\n",
    "        avg_rmse = np.mean((neg_mses*-1)**0.5)\n",
    "        avg_r_sq = np.mean(r_squares)\n",
    "        print(\"Model performance for {} model predicting {}:\".format(\n",
    "            current_model_name, outcome))\n",
    "        print(\"r-square: {:.4f}    RMSE: {:.4f}\".format(avg_r_sq, avg_rmse))\n",
    "    print(\"\")\n",
    "\n",
    "# word count is completly irrelevant to story ratings...\n",
    "# if it stays this way I could just run a MANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e1504",
   "metadata": {},
   "source": [
    "## ANOVA Model Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a72b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, figsize=(10, 20))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "sns.boxplot(x=\"preset_label\", y=\"tss_coh\", data=aiss, ax=axes[0])\n",
    "sns.boxplot(x=\"preset_label\", y=\"tss_avoid_rep\", data=aiss, ax=axes[1])\n",
    "sns.boxplot(x=\"preset_label\", y=\"tss_pac\", data=aiss, ax=axes[2])\n",
    "sns.boxplot(x=\"preset_label\", y=\"tss_cre\", data=aiss, ax=axes[3])\n",
    "sns.boxplot(x=\"preset_label\", y=\"tss_conch\", data=aiss, ax=axes[4])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, figsize=(10, 20))\n",
    "fig.tight_layout(pad=5.0)\n",
    "plt.grid(False)\n",
    "\n",
    "sns.boxplot(x=\"prompt_label\", y=\"tss_coh\", data=aiss, ax=axes[0])\n",
    "sns.boxplot(x=\"prompt_label\", y=\"tss_avoid_rep\", data=aiss, ax=axes[1])\n",
    "sns.boxplot(x=\"prompt_label\", y=\"tss_pac\", data=aiss, ax=axes[2])\n",
    "sns.boxplot(x=\"prompt_label\", y=\"tss_cre\", data=aiss, ax=axes[3])\n",
    "sns.boxplot(x=\"prompt_label\", y=\"tss_conch\", data=aiss, ax=axes[4])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def determine_outliers(df, var, distance=3, mode=\"print\"):\n",
    "    q1 = df[var].quantile(0.25)\n",
    "    q3 = df[var].quantile(0.75)\n",
    "\n",
    "    iqr = q3-q1\n",
    "    outlier_lower = q1 - (iqr*distance)\n",
    "    outlier_upper = q3 + (iqr*distance)\n",
    "    if mode == \"print\":\n",
    "        print(\"25th Percentile (Q1): {:.2f}\\n75th Percentile (Q3): {:.2f}\\nIQR: {:.2f}\".format(\n",
    "            q1, q3, iqr))\n",
    "        print(\"Will count cases as outlier with values less than {:.2f} or more than {:.2f}.\"\n",
    "              .format(outlier_lower, outlier_upper))\n",
    "        mask_outlier = (df[var] < outlier_lower) | (df[var] > outlier_upper)\n",
    "        if df[mask_outlier].shape[0] == 0:\n",
    "            print(\"With these criteria there are no outlier in the data\")\n",
    "        else:\n",
    "            print(\"Showing outliers\")\n",
    "            print(df[mask_outlier][var])\n",
    "    else:\n",
    "        print(\"Mode must be 'print'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302212ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers for Presets\n",
    "\n",
    "# Outliers Coherence\n",
    "print(\"Exterme outliers on tss_coh, Basic Coherence preset\")\n",
    "determine_outliers(aiss[aiss[\"preset_label\"] ==\n",
    "                        \"Basic Coherence\"], \"tss_coh\")\n",
    "\n",
    "# Outliers Repitition\n",
    "print(\"\\nExterme outliers on tss_rep, Morpho preset\")\n",
    "determine_outliers(aiss[aiss[\"preset_label\"] ==\n",
    "                        \"Morpho\"], \"tss_avoid_rep\")\n",
    "\n",
    "# Outliers pace\n",
    "print(\"\\nExterme outliers on tss_pac, Ace of Spade preset\")\n",
    "determine_outliers(aiss[aiss[\"preset_label\"] == \"Ace of Spade\"], \"tss_pac\")\n",
    "\n",
    "# Outliers creativity\n",
    "print(\"\\nExterme outliers on tss_cre, Ouroboros preset\")\n",
    "determine_outliers(aiss[aiss[\"preset_label\"] == \"Ouroboros\"], \"tss_cre\")\n",
    "\n",
    "# Outliers consistent characterization\n",
    "print(\"\\nExterme outliers on tss_pac, Ouroboros\")\n",
    "determine_outliers(aiss[aiss[\"preset_label\"] ==\n",
    "                        \"Ouroboros\"], \"tss_conch\")\n",
    "\n",
    "# Outliers for Prompts\n",
    "\n",
    "# Pace\n",
    "print(\"\\nExterme outliers on tss_avoid rep, Horror prompt\")\n",
    "determine_outliers(aiss[aiss[\"prompt_label\"] == \"Horror\"], \"tss_avoid_rep\")\n",
    "\n",
    "# Creativity\n",
    "print(\"\\nExterme outliers on tss_cre, Horror prompt\")\n",
    "determine_outliers(aiss[aiss[\"prompt_label\"] == \"Horror\"], \"tss_cre\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tss_no_out = aiss[~(aiss.index == 7)].copy()\n",
    "tss_no_out = aiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b8df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normality\n",
    "def qqs_over_groups_and_vars(df, group_label, vars_li, size=(15, 15)):\n",
    "    groups_li = df[group_label].unique()\n",
    "    fig, axes = plt.subplots(len(groups_li), len(vars_li), figsize=size)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    plt.grid(False)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for group, var in itertools.product(groups_li, vars_li):\n",
    "        stats.probplot(df[df[group_label] == group][var],\n",
    "                       dist=\"norm\", plot=axes[y, x])\n",
    "        axes[y, x].set_title(group + \" - \" + var)\n",
    "        if x < (len(vars_li)-1):\n",
    "            x += 1\n",
    "        else:\n",
    "            x = 0\n",
    "            y += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9d12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qqs_over_groups_and_vars(tss_no_out, \"preset_label\", outcome_li, size=(20, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqs_over_groups_and_vars(tss_no_out, \"prompt_label\", outcome_li, size=(20, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4d389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking if F-test ist robust to heteroscedacity\n",
    "# Taking recommended approach from Blanca et al., 2018\n",
    "def anova_check_homoscedacity(y_var, group_var, df):\n",
    "    var_ser = pd.Series(index=df[group_var].unique(), dtype=float)\n",
    "\n",
    "    for group in df[group_var].unique():\n",
    "        var_ser[group] = df[df[group_var] == group][y_var].var()\n",
    "\n",
    "    min_var = (var_ser.idxmin(), var_ser.min())\n",
    "    max_var = (var_ser.idxmax(), var_ser.max())\n",
    "    var_ratio = max_var[1]/min_var[1]\n",
    "    print(\"Smallest variance for {}: {:.2f}\".format(min_var[0], min_var[1]))\n",
    "    print(\"Largest variance for {}: {:.2f}\".format(max_var[0], max_var[1]))\n",
    "    print(\"Variance ratio for: {:.2f}\".format(var_ratio))\n",
    "\n",
    "    if var_ratio <= 1.5:\n",
    "        print(\"Variance ratio is smaller or equal to 1.5, F-test will be robust.\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Variance ratio is larger 1.5. Now doing additional checks to see if F-test is robust.\")\n",
    "\n",
    "    # Create dataframe with variance and group sizes\n",
    "    var_n_df = var_ser.to_frame(name=\"var\")\n",
    "    var_n_df[\"n\"] = df.value_counts(subset=group_var)\n",
    "    # get correlation between correlation and variance\n",
    "    corr_var_n = var_n_df[[\"var\", \"n\"]].corr().iloc[1, 0]\n",
    "\n",
    "    if (corr_var_n >= 0) and (corr_var_n <= 0.5):\n",
    "        print(\"Correlation between sample size and variance (pairing) is {:.2f}. That is between 0 and .5. F-test should be robust\".\n",
    "              format(corr_var_n))\n",
    "        return\n",
    "    else:\n",
    "        print(\"Correlation between sample size and variance (pairing) is {:.2f}. That is below 0 or over .5.\".\n",
    "              format(corr_var_n), \"Continuing with further checks...\")\n",
    "\n",
    "    # Compute coefficient of sample size variation\n",
    "    coeff_n = var_n_df[\"var\"].std()/var_n_df[\"var\"].mean()\n",
    "    if (corr_var_n > 0.5) and (coeff_n > .33) and (var_ratio > 2):\n",
    "        print(\"Pairing is {:.2f}, so larger than .5,\".format(corr_var_n),\n",
    "              \",coefficient of sample size variation is {:.2f}, larger than .33,\".format(\n",
    "                  coeff_n),\n",
    "              \"and variance ratio is {:.2f}, larger than 2.\".format(var_ratio),\n",
    "              \"F-test is too conserative (hurting power)\")\n",
    "    elif (corr_var_n < 0) and (corr_var_n >= -0.5) and (coeff_n > .16) and (var_ratio > 2):\n",
    "        print(\"Pairing is {:.2f}, so smaller than 0 and larger than or equal to -.5,\".format(corr_var_n),\n",
    "              \",coefficient of sample size variation is {:.2f}, larger than .16,\".format(\n",
    "                  coeff_n),\n",
    "              \"and variance ratio is {:.2f}, larger than 2.\".format(var_ratio),\n",
    "              \"F-test is too liberal (real alpha might be as high as .1 if variance ratio is 9 or smaller).\")\n",
    "    elif (corr_var_n < -0.5):\n",
    "        print(\"Pairing is {:.2f}, so smaller than -.5.\".format(corr_var_n),\n",
    "              \"F-test is too liberal (real alpha might be as high as .2 if variance ratio is 9 or smaller).\")\n",
    "    else:\n",
    "        print(\"Pairing is {:.2f}, coefficient of sample size variation is {:.2f}, variance ratio is {:.2f}.\"\n",
    "              .format(corr_var_n, coeff_n, var_ratio),\n",
    "              \"This specific combination should have robust F-test, but look into the paper\",\n",
    "              \"('Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit?', Blanca et al., 2018)\",\n",
    "              \"to be sure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b876c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in outcome_li:\n",
    "    print(\"Checks for {}\".format(outcome))\n",
    "    print(\"Preset\")\n",
    "    anova_check_homoscedacity(outcome, \"preset_label\", tss_no_out)\n",
    "    print(\"\\nPrompt\")\n",
    "    anova_check_homoscedacity(outcome, \"prompt_label\", tss_no_out)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433b98e",
   "metadata": {},
   "source": [
    "## Running the ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf77aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_df = pd.DataFrame()\n",
    "\n",
    "# if heteroscedacity, run with fit(cov_type='HC3') and anova_lm(anova_mod, typ=2, robust='HC3')\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    print(\"\\033[1m{}\\033[0m\".format(outcome))\n",
    "    ols_formula = outcome + \\\n",
    "        \" ~ C(preset_label, Sum) + C(prompt_label, Sum) + C(sample, Treatment(0))\"\n",
    "    ols_formula2 = outcome + \\\n",
    "        \" ~ C(preset_label, Sum(0)) + C(prompt_label, Sum(0)) + C(sample, Treatment(0))\"\n",
    "    anova_mod = ols(\n",
    "        ols_formula, tss_no_out).fit(cov_type='HC3')\n",
    "    anova_mod2 = ols(\n",
    "        ols_formula2, tss_no_out).fit(cov_type='HC3')\n",
    "    print(sm.stats.anova_lm(anova_mod, typ=2, robust='HC3'))\n",
    "    print(anova_mod.summary(alpha=0.1))\n",
    "\n",
    "    print(\"\\nDeviation contrasts for\\n{}:\\tcoef: {:.3f}\\tp: {:.3f}\"\n",
    "          .format(anova_mod2.params.index[7], anova_mod2.params[7], anova_mod2.pvalues[7]),\n",
    "          \"\\n{}:\\tcoef: {:.3f}\\tp: {:.3f}\"\n",
    "          .format(anova_mod2.params.index[10], anova_mod2.params[10], anova_mod2.pvalues[10]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    params_df[outcome] = anova_mod.params\n",
    "    params_df[outcome + \" p-value\"] = anova_mod.pvalues\n",
    "    params_df[outcome + \" 90% CI Lower\"] = anova_mod.conf_int(alpha=0.1)[0]\n",
    "\n",
    "    params_df.loc[anova_mod2.params.index[7], outcome] = anova_mod2.params[7]\n",
    "    params_df.loc[anova_mod2.params.index[7],\n",
    "                  outcome + \" p-value\"] = anova_mod2.pvalues[7]\n",
    "    params_df.loc[anova_mod2.params.index[7], outcome +\n",
    "                  \" 90% CI Lower\"] = anova_mod2.conf_int(alpha=0.1)[0][7]\n",
    "\n",
    "    params_df.loc[anova_mod2.params.index[10], outcome] = anova_mod2.params[10]\n",
    "    params_df.loc[anova_mod2.params.index[10],\n",
    "                  outcome + \" p-value\"] = anova_mod2.pvalues[10]\n",
    "    params_df.loc[anova_mod2.params.index[10], outcome +\n",
    "                  \" 90% CI Lower\"] = anova_mod2.conf_int(alpha=0.1)[0][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454db8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df.index = params_df.index.str.replace(\n",
    "    r'C\\(.*[ST]\\.(.*)\\]', r'\\1', regex=True)\n",
    "\n",
    "# Transform 90% CI lower bound to 90% CI margin of error\n",
    "for outcome in outcome_li:\n",
    "    params_df[outcome + \" 90% CI Lower\"] = params_df[outcome] - \\\n",
    "        params_df[outcome + \" 90% CI Lower\"]\n",
    "params_df.columns = params_df.columns.str.replace(\n",
    "    \"90% CI Lower\", \"90% CI margin\", regex=False)\n",
    "\n",
    "presets_li = list(tss_no_out[\"preset_label\"].unique())\n",
    "prompts_li = list(tss_no_out[\"prompt_label\"].unique())\n",
    "\n",
    "order_index = [\"Intercept\", \"Panel\"]\n",
    "order_index.extend(presets_li)\n",
    "order_index.extend(prompts_li)\n",
    "\n",
    "params_df = params_df.reindex(order_index)\n",
    "\n",
    "cols_order = []\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    # no adjustement for p necessary for sample source\n",
    "    params_df.loc[\"Panel\", outcome +\n",
    "                  \" adj_p\"] = params_df.loc[\"Panel\", outcome + \" p-value\"]\n",
    "    # adjusted ps for presets\n",
    "    params_df.loc[presets_li, outcome + \" adj_p\"] = fdrcorrection(\n",
    "        params_df.loc[presets_li, outcome + \" p-value\"], alpha=0.1)[1]\n",
    "    # adjusted ps for prompts\n",
    "    params_df.loc[prompts_li, outcome + \" adj_p\"] = fdrcorrection(\n",
    "        params_df.loc[prompts_li, outcome + \" p-value\"], alpha=0.1)[1]\n",
    "\n",
    "    cols_order.extend([outcome, outcome + \" p-value\",\n",
    "                       outcome + \" adj_p\", outcome + \" 90% CI margin\"])\n",
    "\n",
    "params_df = params_df[cols_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e261940",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_p_cols = params_df.columns.str.extractall(\"(.*adj_p)\").values.flatten()\n",
    "mask_sig = (params_df[adj_p_cols] < 0.1).any(axis=1)\n",
    "\n",
    "params_df[mask_sig]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_no_out[\"preset_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [\"Coherence\", \"Creativity\", \"Avoiding Repitition\", \"Pace\"]\n",
    "\n",
    "# # create dicts with a key for each preset with an empty list as value for each\n",
    "# marginal_means_dict = {preset: [] for preset in params_df[1:8].index}\n",
    "# yerr_dict = {preset: [] for preset in params_df[1:8].index}\n",
    "# #colors = [\"tab:blue\", \"tab:green\", \"tab:red\", \"tab:orange\"]\n",
    "\n",
    "# for preset, outcome in itertools.product(marginal_means_dict.keys(), outcome_li):\n",
    "#     marginal_means_dict[preset].append(params_df.loc[\"Intercept\", outcome] + params_df.loc[preset, outcome])\n",
    "#     yerr_dict[preset].append(params_df.loc[preset, outcome + \" 90% CI margin\"])\n",
    "\n",
    "# figure = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# x = np.arange(len(labels)) # label locations\n",
    "# width = 0.35 # width of bars\n",
    "\n",
    "# plt.bar(x-width/2, marginal_means_dict[\"Genesis\"], width,\n",
    "#         yerr = yerr_dict[\"Genesis\"], label = \"Genesis\", color = \"tab:blue\")\n",
    "# plt.bar(x+width/2, marginal_means_dict[\"Ouroboros\"], width,\n",
    "#         yerr = yerr_dict[\"Ouroboros\"], label = \"Ouroboros\", color = \"tab:orange\")\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# pos = -0.4\n",
    "# for outcome in outcome_li:\n",
    "#     grand_mean = params_df.loc[\"Intercept\", outcome]\n",
    "#     ax = plt.plot([pos, pos+0.8], [grand_mean, grand_mean], '--', color = \"black\", alpha = 0.65)\n",
    "#     if i == 0:\n",
    "#         ax[0].set_label(\"Grand Mean (all Presets)\")\n",
    "#     i += 1\n",
    "#     pos += 1\n",
    "\n",
    "# plt.ylim(1,5)\n",
    "# plt.ylabel(\"Marginal Means (Community Sample)\", fontsize = 16)\n",
    "# plt.xticks(x, labels, fontsize = 16)\n",
    "\n",
    "# plt.legend(frameon=False, fontsize = 16, loc='upper center', ncol = 3)\n",
    "# leg = plt.gca().get_legend()\n",
    "# plt.grid(False)\n",
    "# #plt.title(\"Genesis & Low Rider\")\n",
    "# #figure.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# figure.savefig('graphs/gen_our_1.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb7ee5",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Coherence\", \"Creativity\",\n",
    "          \"Avoiding Repitition\", \"Pace\", \"Consistent Characters\"]\n",
    "presets_1 = [\"Genesis\", \"Ouroboros\",\n",
    "             \"Basic Coherence\", \"Low Rider\", \"All-Nighter\"]\n",
    "presets_2 = [\"Morpho\", \"Ace of Spade\", \"Fandango\"]\n",
    "\n",
    "preset_to_graph = [presets_1, presets_2]\n",
    "\n",
    "max_n_presets = max([len(x) for x in preset_to_graph])\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "# fig.tight_layout(pad=5.0)\n",
    "plt.setp(axes, ylim=(-1, 1))\n",
    "fig.text(0.02, 0.5, \"Marginal Means (Community Sample)\",\n",
    "         va='center', rotation='vertical', fontsize=16)\n",
    "\n",
    "i = 0\n",
    "for pre_li in preset_to_graph:\n",
    "\n",
    "    # create dicts with a key for each outcome with an empty list as value for each\n",
    "    # values are centered around the mean for the community sample (!)\n",
    "    # so a value of 0 is exactly the expected mean for the community sample\n",
    "    marginal_means_dict = {outcome: [] for outcome in outcome_li}\n",
    "    yerr_dict = {outcome: [] for outcome in outcome_li}\n",
    "\n",
    "    prod_presets_outcomes = itertools.product(pre_li, outcome_li)\n",
    "\n",
    "    for preset, outcome in prod_presets_outcomes:\n",
    "        marginal_means_dict[outcome].append(params_df.loc[preset, outcome])\n",
    "        yerr_dict[outcome].append(\n",
    "            params_df.loc[preset, outcome + \" 90% CI margin\"])\n",
    "\n",
    "    # Compute difference in length to longest row\n",
    "    diff_len = max_n_presets - len(pre_li)\n",
    "\n",
    "    # fill up dictonaries with 0 if less values than the longest row\n",
    "    if diff_len > 0:\n",
    "        for outcome in outcome_li:\n",
    "            marginal_means_dict[outcome].extend([0]*diff_len)\n",
    "            yerr_dict[outcome].extend([0]*diff_len)\n",
    "\n",
    "    x = np.arange(len(marginal_means_dict[\"tss_cre\"]))  # label locations\n",
    "    width = 0.15  # width of bars\n",
    "\n",
    "    cur_ax = axes[i]\n",
    "    n_presets = len(pre_li)\n",
    "\n",
    "    x_labels = pre_li\n",
    "    x_labels.extend([\"\"]*diff_len)\n",
    "\n",
    "    cur_ax.set_xticks(x)\n",
    "    cur_ax.set_xticklabels(x_labels, fontsize=16)\n",
    "\n",
    "    cur_ax.bar(x-0.3, marginal_means_dict[\"tss_coh\"], width,\n",
    "               yerr=yerr_dict[\"tss_coh\"], label=\"Coherence\", color=\"tab:blue\")\n",
    "\n",
    "    cur_ax.bar(x-0.15, marginal_means_dict[\"tss_cre\"], width,\n",
    "               yerr=yerr_dict[\"tss_cre\"], label=\"Creativity\", color=\"tab:green\")\n",
    "\n",
    "    cur_ax.bar(x, marginal_means_dict[\"tss_avoid_rep\"], width,\n",
    "               yerr=yerr_dict[\"tss_avoid_rep\"], label=\"Avoiding Repetition\", color=\"tab:red\")\n",
    "\n",
    "    cur_ax.bar(x+0.15, marginal_means_dict[\"tss_pac\"], width,\n",
    "               yerr=yerr_dict[\"tss_pac\"], label=\"Pace\", color=\"tab:orange\")\n",
    "\n",
    "    cur_ax.bar(x+0.3, marginal_means_dict[\"tss_conch\"], width,\n",
    "               yerr=yerr_dict[\"tss_pac\"], label=\"Consistent Characters\", color=\"tab:purple\")\n",
    "\n",
    "    cur_ax.grid(False)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "axes[0].legend(frameon=False, fontsize=16, loc='upper center',\n",
    "               ncol=3, bbox_to_anchor=(0.6, 1))\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('graphs/gen_presets_preview.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for Community vs Panel\n",
    "\n",
    "# create dicts with a key for pe sample source with an empty list as value for each\n",
    "marginal_means_dict = {\"Community\": [], \"Panel\": []}\n",
    "yerr_dict = {\"Community\": [], \"Panel\": []}\n",
    "\n",
    "outcome_labels = [\"Coherence\", \"Creativity\",\n",
    "                  \"Avoiding\\nRepetition\", \"Pace\", \"Consistent\\nCharacterization\"]\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    marginal_means_dict[\"Community\"].append(\n",
    "        params_df.loc[\"Intercept\", outcome])\n",
    "    yerr_dict[\"Community\"].append(\n",
    "        params_df.loc[\"Intercept\", outcome + \" 90% CI margin\"])\n",
    "\n",
    "    marginal_means_dict[\"Panel\"].append(\n",
    "        params_df.loc[\"Intercept\", outcome] + params_df.loc[\"Panel\", outcome])\n",
    "    yerr_dict[\"Panel\"].append(\n",
    "        params_df.loc[\"Panel\", outcome + \" 90% CI margin\"])\n",
    "\n",
    "figure = plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(marginal_means_dict[\"Community\"]))  # label locations\n",
    "width = 0.4  # width of bars\n",
    "\n",
    "plt.bar(x-0.2, marginal_means_dict[\"Community\"], width,\n",
    "        yerr=yerr_dict[\"Community\"], label=\"Nai Users\", color=\"tab:blue\")\n",
    "plt.bar(x+0.2, marginal_means_dict[\"Panel\"], width,\n",
    "        yerr=yerr_dict[\"Panel\"], label=\"Panel Participants\", color=\"tab:orange\")\n",
    "\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.ylabel(\"Marginal Means\", fontsize=16)\n",
    "plt.xticks(x, outcome_labels, fontsize=16)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=16, loc='upper right')\n",
    "plt.grid(False)\n",
    "#plt.title(\"Genesis & Low Rider\")\n",
    "# figure.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "figure.savefig('graphs/community_vs_panel.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef27f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph for prompts\n",
    "\n",
    "# create dicts with a key for each outcome with an empty list as value for each\n",
    "marginal_means_dict = {outcome: [] for outcome in outcome_li}\n",
    "yerr_dict = {outcome: [] for outcome in outcome_li}\n",
    "\n",
    "for prompt, outcome in itertools.product(prompts_li, outcome_li):\n",
    "    marginal_means_dict[outcome].append(params_df.loc[prompt, outcome])\n",
    "    yerr_dict[outcome].append(\n",
    "        params_df.loc[prompt, outcome + \" 90% CI margin\"])\n",
    "\n",
    "figure = plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(marginal_means_dict[\"tss_cre\"]))  # label locations\n",
    "width = 0.15  # width of bars\n",
    "\n",
    "plt.bar(x-0.3, marginal_means_dict[\"tss_coh\"], width,\n",
    "        yerr=yerr_dict[\"tss_coh\"], label=\"Coherence\", color=\"tab:blue\")\n",
    "\n",
    "plt.bar(x-0.15, marginal_means_dict[\"tss_cre\"], width,\n",
    "        yerr=yerr_dict[\"tss_cre\"], label=\"Creativity\", color=\"tab:green\")\n",
    "\n",
    "plt.bar(x, marginal_means_dict[\"tss_avoid_rep\"], width,\n",
    "        yerr=yerr_dict[\"tss_avoid_rep\"], label=\"Avoiding Repetition\", color=\"tab:red\")\n",
    "\n",
    "plt.bar(x+0.15, marginal_means_dict[\"tss_pac\"], width,\n",
    "        yerr=yerr_dict[\"tss_pac\"], label=\"Pace\", color=\"tab:orange\")\n",
    "\n",
    "plt.bar(x+0.3, marginal_means_dict[\"tss_conch\"], width,\n",
    "        yerr=yerr_dict[\"tss_pac\"], label=\"Consistent Characters\", color=\"tab:purple\")\n",
    "\n",
    "plt.ylim(-1, 1)\n",
    "plt.ylabel(\"Marginal Means (Community Sample)\", fontsize=16)\n",
    "plt.xticks(x, prompts_li, fontsize=16)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=16, loc='upper center',\n",
    "           ncol=3, bbox_to_anchor=(0.6, 1))\n",
    "# plt.legend(frameon=False, bbox_to_anchor = (1,.9), fontsize = 16)\n",
    "plt.grid(False)\n",
    "#plt.title(\"Genesis & Low Rider\")\n",
    "# figure.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "figure.savefig('graphs/gen_prompts.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0310f1c",
   "metadata": {},
   "source": [
    "# Analyze Consistency of Story Aspects Across Presets & Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af0e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for outcome in outcome_li:\n",
    "    print((\"_\"*75) + \"\\n\")\n",
    "    print(\"\\033[1m{}\\033[0m\".format(outcome))\n",
    "\n",
    "    homo_res = pg.homoscedasticity(\n",
    "        tss_no_out, dv=outcome, group=\"preset_label\", method=\"levene\", alpha=0.1)\n",
    "    print(\"Omnibus Test for homoscedasticity across presets\")\n",
    "    print(homo_res.round(3))\n",
    "\n",
    "    if homo_res.iloc[0, 2] == False:\n",
    "        print(\"\\nVariances are not equal, doing posthoc tests\")\n",
    "        print(f\"Average SD: {tss_no_out[outcome].std():.2f}\")\n",
    "        print(\"\\nPresets with adjusted p-vals < .15 displayed below:\")\n",
    "\n",
    "        posthoc_dict = {}\n",
    "        for preset in presets_li:\n",
    "            data_preset = tss_no_out[tss_no_out[\"preset_label\"]\n",
    "                                     == preset][outcome].to_numpy()\n",
    "            data_rest = tss_no_out[tss_no_out[\"preset_label\"]\n",
    "                                   != preset][outcome].to_numpy()\n",
    "            posthoc_dict[preset] = pg.homoscedasticity(\n",
    "                [data_preset, data_rest], method=\"levene\", alpha=0.1)\n",
    "\n",
    "        ps_li = []\n",
    "        for dv in posthoc_dict:\n",
    "            ps_li.append(posthoc_dict[dv].iloc[0, 1])\n",
    "        adj_ps_li = fdrcorrection(ps_li, alpha=0.1)[1]\n",
    "\n",
    "        i = 0\n",
    "        for dv in posthoc_dict:\n",
    "            posthoc_dict[dv].loc[\"levene\",\n",
    "                                 \"sd\"] = tss_no_out[tss_no_out[\"preset_label\"] == dv][outcome].std()\n",
    "            posthoc_dict[dv].loc[\"levene\", \"adj_p\"] = adj_ps_li[i]\n",
    "            if posthoc_dict[dv].loc[\"levene\", \"adj_p\"] < 0.15:\n",
    "                print(f\"\\n{dv}\")\n",
    "                print(posthoc_dict[dv].round(3))\n",
    "            i += 1\n",
    "\n",
    "    homo_res = pg.homoscedasticity(\n",
    "        tss_no_out, dv=outcome, group=\"prompt_label\", method=\"levene\", alpha=0.1)\n",
    "    print(\"-\"*75)\n",
    "    print(\"\\nOmnibus Test for homoscedasticity across prompts\")\n",
    "    print(f\"{homo_res.round(3)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7844b",
   "metadata": {},
   "source": [
    "## Visualize Findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edafe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_over_groups(df, var, var_name, group_label, groups_li,\n",
    "                     bins_n=10, xlim=(-3, 3), size=(15, 15),\n",
    "                     plot_avg=True):\n",
    "    n_plots = len(groups_li)+1 if plot_avg else len(groups_li)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=size)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    x = 0\n",
    "\n",
    "    if plot_avg:\n",
    "        df[var].plot.hist(ax=axes[x], bins=bins_n)\n",
    "        df[var].plot.kde(ax=axes[x], secondary_y=True)\n",
    "        axes[x].set_xlim(xlim)\n",
    "        axes[x].set_title(f\"{var_name} - Average\")\n",
    "        plt.grid(False)\n",
    "        x += 1\n",
    "\n",
    "    for group in groups_li:\n",
    "        df_group = df[df[group_label] == group]\n",
    "        df_group[var].plot.hist(ax=axes[x], bins=bins_n)\n",
    "        df_group[var].plot.kde(ax=axes[x], secondary_y=True)\n",
    "        axes[x].set_xlim(xlim)\n",
    "        axes[x].set_title(f\"{var_name} - {group}\")\n",
    "        plt.grid(False)\n",
    "        x += 1\n",
    "\n",
    "\n",
    "def box_over_groups(df, var, var_name, group_label, groups_li,\n",
    "                    ylim=(-3, 3), size=(15, 15),\n",
    "                    plot_avg=True, save_plot=False):\n",
    "    n_plots = len(groups_li)+1 if plot_avg else len(groups_li)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=size)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    x = 0\n",
    "\n",
    "    if plot_avg:\n",
    "        sns.boxplot(y=df[var], ax=axes[x])\n",
    "        axes[x].set_ylim(ylim)\n",
    "        axes[x].set_title(f\"{var_name} - Average\")\n",
    "        axes[x].grid(False)\n",
    "        x += 1\n",
    "\n",
    "    for group in groups_li:\n",
    "        df_group = df[df[group_label] == group]\n",
    "        sns.boxplot(y=df_group[var], ax=axes[x])\n",
    "        axes[x].set_ylim(ylim)\n",
    "        axes[x].set_title(f\"{var_name} - {group}\")\n",
    "        axes[x].grid(False)\n",
    "        x += 1\n",
    "\n",
    "    if save_plot:\n",
    "        fig.savefig(save_plot, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_over_groups(tss_no_out, \"tss_coh\", \"Coherence\",\n",
    "                 \"preset_label\", [\"All-Nighter\"],\n",
    "                 size=(15, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_over_groups(tss_no_out, \"tss_coh\", \"Coherence\",\n",
    "                \"preset_label\", [\"All-Nighter\"],\n",
    "                size=(15, 6), save_plot=\"graphs/box_coh.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5eab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_over_groups(tss_no_out, \"tss_pac\", \"Coherence\",\n",
    "                 \"preset_label\", [\"Low Rider\", \"Morpho\"],\n",
    "                 size=(15, 5), bins_n=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9928ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_over_groups(tss_no_out, \"tss_pac\", \"Pace\",\n",
    "                \"preset_label\", [\"Low Rider\", \"Morpho\"],\n",
    "                size=(15, 6), save_plot=\"graphs/box_pac.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_no_out[[\"tss_coh\", \"tss_avoid_rep\", \"tss_pac\", \"tss_cre\", \"tss_conch\",\n",
    "            \"tss_cre_4\",\n",
    "            \"tss_qua_1\", \"tss_qua_2\"]].corr(method=\"kendall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed087e25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "items_descr[[\"tss_cre_4\", \"tss_qua_1\", \"tss_qua_2\", \"tss_qua_3\",\n",
    "             \"tss_qua_5\", \"tss_qua_6\", \"tss_qua_7\", \"tss_qua_8\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual = tss_no_out.groupby('preset_label').mean(\n",
    "# )[[\"tss_qua_2\", \"tss_qua_1\", \"tss_qua_3\"]].sort_values(\"tss_qua_1\")\n",
    "\n",
    "# figure = plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"tss_qua_1\", y=\"preset_label\", data=tss_no_out)\n",
    "#plt.bar(qual.index, qual[\"tss_qua_1\"])\n",
    "# plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b863f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 2, figsize=(10, 30))\n",
    "fig.tight_layout(pad=5.0)\n",
    "plt.grid(False)\n",
    "\n",
    "sns.regplot(data=tss_no_out, y=\"tss_coh\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[0, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_coh\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[0, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_cre\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[1, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_cre\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[1, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_avoid_rep\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[2, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_avoid_rep\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[2, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_pac\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[3, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_pac\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[3, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_conch\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[4, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_conch\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[4, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_qua_1\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[5, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_qua_1\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[5, 1])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_qua_2\",\n",
    "            x=\"read_consesus\", lowess=True, ax=axes[6, 0])\n",
    "sns.regplot(data=tss_no_out, y=\"tss_qua_2\",\n",
    "            x=\"read_fre\", lowess=True, ax=axes[6, 1])\n",
    "for ax in fig.axes:\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8809bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up k-fold cross validation\n",
    "\n",
    "kf = KFold(10, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining predictors for models\n",
    "aiss[\"read_cent\"] = aiss[\"read_consesus\"].apply(\n",
    "    lambda x: x-aiss[\"read_consesus\"].mean())  # centering\n",
    "\n",
    "aiss[\"read_cent**2\"] = aiss[\"read_cent\"]*aiss[\"read_cent\"]\n",
    "aiss[\"read_cent**3\"] = aiss[\"read_cent\"]**3\n",
    "aiss[\"read_cent**4\"] = aiss[\"read_cent\"]**4\n",
    "aiss[\"read_cent**5\"] = aiss[\"read_cent\"]**5\n",
    "\n",
    "lin_model = linreg()\n",
    "\n",
    "pred_li = [(\"linear\", \"read_cent\"), (\"quadratic\", \"read_cent**2\"),\n",
    "           (\"cubic\", \"read_cent**3\"), (\"quartic\", \"read_cent**4\"),\n",
    "           (\"quintic\", \"read_cent**5\")]\n",
    "outcome_li = [\"tss_coh\", \"tss_cre\", \"tss_avoid_rep\",\n",
    "              \"tss_pac\", \"tss_conch\", \"tss_qua_1\", \"tss_qua_2\",\n",
    "              \"tss_sty_5\", \"tss_sty_5\"]\n",
    "\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    y = aiss[outcome]\n",
    "    current_preds_col = []\n",
    "\n",
    "    for pred in pred_li:\n",
    "        current_preds_col.append(pred[1])\n",
    "        x = aiss.loc[:, current_preds_col]\n",
    "\n",
    "        current_model_name = pred[0]\n",
    "\n",
    "        cross_val = cross_validate(lin_model, x, y,\n",
    "                                   scoring=[\"neg_mean_squared_error\", \"r2\"], cv=kf)\n",
    "\n",
    "        neg_mses = cross_val[\"test_neg_mean_squared_error\"]\n",
    "        r_squares = cross_val[\"test_r2\"]\n",
    "        avg_rmse = np.mean((neg_mses*-1)**0.5)\n",
    "        avg_r_sq = np.mean(r_squares)\n",
    "        print(\"Model performance for {} model predicting {}:\".format(\n",
    "            current_model_name, outcome))\n",
    "        print(\"r-square: {:.4f}    RMSE: {:.4f}\".format(avg_r_sq, avg_rmse))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_li = [\"tss_coh\", \"tss_cre\", \"tss_avoid_rep\", \"tss_pac\", \"tss_conch\"]\n",
    "\n",
    "marg_means_df = params_df.loc[[\"Intercept\", \"Genesis\", \"Ouroboros\", \"Basic Coherence\", \"Low Rider\",\n",
    "                               \"All-Nighter\", \"Morpho\", \"Ace of Spade\", \"Fandango\"],\n",
    "                              [\"tss_coh\", \"tss_cre\", \"tss_avoid_rep\", \"tss_pac\", \"tss_conch\",\n",
    "                               \"tss_coh 90% CI margin\", \"tss_cre 90% CI margin\",\n",
    "                               \"tss_avoid_rep 90% CI margin\", \"tss_pac 90% CI margin\",\n",
    "                               \"tss_conch 90% CI margin\",\n",
    "                               \"tss_coh adj_p\", \"tss_cre adj_p\",\n",
    "                               \"tss_avoid_rep adj_p\", \"tss_pac adj_p\",\n",
    "                               \"tss_conch adj_p\"]].copy()\n",
    "\n",
    "for outcome in outcome_li:\n",
    "    marg_means_df.loc[\n",
    "        [\"Genesis\", \"Ouroboros\", \"Basic Coherence\", \"Low Rider\", \"All-Nighter\", \"Morpho\", \"Ace of Spade\", \"Fandango\"], outcome] = marg_means_df.loc[\n",
    "        [\"Genesis\", \"Ouroboros\", \"Basic Coherence\", \"Low Rider\", \"All-Nighter\", \"Morpho\", \"Ace of Spade\", \"Fandango\"], outcome].apply(\n",
    "        lambda x: marg_means_df.loc[\"Intercept\", outcome]+x)\n",
    "\n",
    "marg_means_df.rename(index={\"Intercept\": \"Grand Mean\"}, inplace=True)\n",
    "marg_means_df.columns = marg_means_df.columns.str.replace(\n",
    "    \"tss_coh\", \"Coherence\")\n",
    "marg_means_df.columns = marg_means_df.columns.str.replace(\n",
    "    \"tss_cre\", \"Creativity\")\n",
    "marg_means_df.columns = marg_means_df.columns.str.replace(\n",
    "    \"tss_avoid_rep\", \"Avoiding Repitition\")\n",
    "marg_means_df.columns = marg_means_df.columns.str.replace(\"tss_pac\", \"Pace\")\n",
    "marg_means_df.columns = marg_means_df.columns.str.replace(\n",
    "    \"tss_conch\", \"Consistent Characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_means_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dac01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update GSheet from Basileus\n",
    "gc = gs.oauth()\n",
    "\n",
    "gsheet = gc.open(\"Preset Analysis\").worksheet(\"Data\")\n",
    "gsheet_df = gd.get_as_dataframe(gsheet, index_col=\"Preset\")\n",
    "gsheet_df.update(marg_means_df)\n",
    "gd.set_with_dataframe(gsheet, gsheet_df, include_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((tss_no_out[\"preset_label\"] == \"Morpho\") &\n",
    "        (tss_no_out[\"tss_coh\"] > 2.55) &\n",
    "        (tss_no_out[\"tss_avoid_rep\"] > 2.21) &\n",
    "        (tss_no_out[\"tss_avoid_rep\"] < 2.70) &\n",
    "        (tss_no_out[\"sample\"] == \"Community\")\n",
    "        )\n",
    "\n",
    "tss_no_out[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94641cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tss_no_out.loc[35, outcome_li])\n",
    "print(tss_no_out.loc[35, \"full_story\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tss_no_out.loc[130, outcome_li])\n",
    "print(tss_no_out.loc[130, \"full_story\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf62433",
   "metadata": {},
   "source": [
    "| Preset               | Performance during continuous story generation<br />(Without user intervention)                                                                             |\n",
    "| :------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Genesis              | Less coherent than the average                                                                                                                              |\n",
    "| Basic Coherence      | Narrow range in terms of Coherence.<br />Most outputs are close to average Coherence.<br />(= Low variance)                                                 |\n",
    "| Ouroboros, Low Rider | Solid - average on all story aspects                                                                                                                        |\n",
    "| Ace of Spade         | Less repetitions than the average                                                                                                                           |\n",
    "| All-Nighter          | Wide range of possible outputs in terms of Coherence.<br />You'll get more incoherent outputs, but also more strongly coherent ones.<br />(= High Variance) |\n",
    "| Morpho               | Major issues with repetitions<br />Low pace (possibly due to repetitions)                                                                                   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "547.85px",
    "left": "1163.2px",
    "right": "20px",
    "top": "120px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
